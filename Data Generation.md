# Data Generation for Training

#### CoGen: 3D Consistent Video Generation via Adaptive Conditioning for Autonomous Driving
* **Authors**: Yong Ji, Zheng Zhu, Zhenyu Zhu, Kaixin Xiong, Meng Lu, Zhihao Li, Lei Zhou, Hongbing Sun, Bowen Wang, Ting Lu
* **Links**: [arXiv:2503.22231](https://arxiv.org/abs/2503.22231)

#### DriveGAN: Towards a Controllable High-Quality Neural Simulation
* **Authors**: Seung Wook Kim, Jonah Philion, Antonio Torralba, Sanja Fidler
* **Links**: [CVPR 2021 Paper](https://openaccess.thecvf.com/content/CVPR2021/html/Kim_DriveGAN_Towards_a_Controllable_High-Quality_Neural_Simulation_CVPR_2021_paper.html) · [arXiv:2104.15060](https://arxiv.org/abs/2104.15060)

#### DriveDreamer: Towards Real-World-Driven World Models for Autonomous Driving
* **Authors**: Xiaofeng Wang, Zheng Zhu, Guan Huang, Xinze Chen, Jiagang Zhu, Jiwen Lu
* **Links**: [arXiv:2309.09777](https://arxiv.org/abs/2309.09777) · [ECCV 2024 Paper](https://link.springer.com/chapter/10.1007/978-3-031-73195-2_4)

#### GAIA-1: A Generative World Model for Autonomous Driving
* **Authors**: Anthony Hu, Lloyd Russell, Hudson Yeo, Zak Murez, George Fedoseev, Alex Kendall, Jamie Shotton, Gianluca Corrado
* **Links**: [arXiv:2309.17080](https://arxiv.org/abs/2309.17080)

#### GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving
* **Authors**: Lloyd Russell, Anthony Hu, Lorenzo Bertoni, George Fedoseev, Jamie Shotton, Elahe Arani, Gianluca Corrado
* **Links**: [arXiv:2503.20523](https://arxiv.org/abs/2503.20523)

#### Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability
* **Authors**: Shenyuan Gao, Jiazhi Yang, Li Chen, Kashyap Chitta, Yihang Qiu, Andreas Geiger, Jun Zhang, Hongyang Li
* **Links**: [NeurIPS 2024 Paper](https://proceedings.neurips.cc/paper/2024/hash/a6a066fb44f2fe0d36cf740c873b8890-Abstract-Conference.html)

#### DrivingDiffusion: Layout-Guided Multi-View Driving Scenarios Video Generation with Latent Diffusion Model
* **Authors**: Xiaofan Li, Yifu Zhang, Xiaoqing Ye
* **Links**: [ECCV 2024 Paper](https://doi.org/10.1007/978-3-031-73229-4_27)

#### FIERY: Future Instance Prediction in Bird’s-Eye View from Surround Monocular Cameras
* **Authors**: Anthony Hu, Zak Murez, Nikhil Mohan, Sofía Dudas, Jeffrey Hawke, Vijay Badrinarayanan, Roberto Cipolla, Alex Kendall
* **Links**: [ICCV 2021 Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Hu_FIERY_Future_Instance_Prediction_in_Birds-Eye_View_From_Surround_Monocular_ICCV_2021_paper.pdf) · [arXiv:2104.10490](https://arxiv.org/abs/2104.10490)

#### UnO: Unsupervised Occupancy Fields for Perception and Forecasting
* **Authors**: Ben Agro, Quinlan Sykora, Sergio Casas, Thomas Gilles, Raquel Urtasun
* **Links**: [CVPR 2024 Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Agro_UnO_Unsupervised_Occupancy_Fields_for_Perception_and_Forecasting_CVPR_2024_paper.html) · [arXiv:2406.08691](https://arxiv.org/abs/2406.08691)

#### GenAD: Generative End-to-End Autonomous Driving
* **Authors**: Ruicong Zheng, Rui Song, Xiaoran Guo, Chubin Zhang, Liang Chen
* **Links**: [arXiv:2402.11502](https://arxiv.org/abs/2402.11502)

#### OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving
* **Authors**: Lei Wang, Wenzheng Zheng, Yiming Ren, Hao Jiang, Zhen Cui, Heng Yu, Jiwen Lu
* **Links**: [arXiv:2405.20337](https://arxiv.org/abs/2405.20337)

#### DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes
* **Authors**: Hengwei Bian, Lingdong Kong, Haozhe Xie, Liang Pan, Yu Qiao, Ziwei Liu
* **Links**: [ICLR 2025 Spotlight](https://openreview.net/forum?id=M7KyLjuN0A) · [arXiv:2410.18084](https://arxiv.org/abs/2410.18084)

#### OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving
* **Authors**: Wenzhao Zheng, Weiliang Chen, Yuanhui Huang, Borui Zhang, Yueqi Duan, Jiwen Lu
* **Links**: [arXiv:2311.16038](https://arxiv.org/abs/2311.16038)

#### Driving in the Occupancy World: Vision-Centric 4D Occupancy Forecasting and Planning via World Models for Autonomous Driving
* **Authors**: Yucheng Yang, Jiangtao Mei, Yican Ma, Shaoyu Du, Wenqi Chen, Yifan Qian, Yuyang Feng, Yi Liu
* **Links**: [arXiv:2406.02387](https://arxiv.org/abs/2406.02387)

#### Learning to Generate Realistic LiDAR Point Clouds
* **Authors**: Vladimir Zyrianov, Xin Zhu, Shuran Wang
* **Links**: [ECCV 2022 Paper](https://link.springer.com/chapter/10.1007/978-3-031-19803-8_3)

#### RangeLDM: Fast Realistic LiDAR Point Cloud Generation
* **Authors**: Qingquan Hu, Zhendong Zhang, Wen Hu
* **Links**: [arXiv:2403.10094](https://arxiv.org/abs/2403.10094)

#### DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation
* **Authors**: Guosheng Zhao, Xiaofeng Wang, Zheng Zhu, Xinze Chen, Guan Huang, Xiaoyi Bao, Xingang Wang
* **Links**: [arXiv:2403.06845](https://arxiv.org/abs/2403.06845)

#### BEVControl: Accurately Controlling Street-View Elements with Multi-Perspective Consistency via BEV Sketch Layout
* **Authors**: Kai Yang, Erkang Ma, Juyuan Peng, Qian Guo, Donghao Lin, Kun Yu
* **Links**: [arXiv:2308.01661](https://arxiv.org/abs/2308.01661)

#### SimGen: Simulator-Conditioned Driving Scene Generation
* **Authors**: Ying Zhou, Ming Simon, Zhimin Peng, Sha Mo, Hong Zhu, Ming Guo, Bolei Zhou
* **Links**: [arXiv:2406.00865](https://arxiv.org/abs/2406.00865)

#### GEM: A Generalizable Ego-Vision Multimodal World Model for Fine-Grained Ego-Motion, Object Dynamics, and Scene Composition Control
* **Authors**: Mohamed Hassan, Stefan Stapf, Ali Rahimi, Pedro Rezende, Yujie Haghighi, David Brüggemann, Ismail Katircioglu, Lin Zhang, Xiang Chen, Subhrajit Saha et al.
* **Links**: [CVPR 2024 Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Hassan_GEM_A_Generalizable_Ego-Vision_Multimodal_World_Model_for_Fine-Grained_Ego-Motion_Object_Dynamics_and_CVPR_2024_paper.html)

#### DrivingWorld: Constructing World Model for Autonomous Driving via Video GPT
* **Authors**: Xuan Hu, Wei Yin, Ming Jia, Ji Deng, Xiaoyan Guo, Qi Zhang, Xian Long, Peter Tan
* **Links**: [arXiv:2412.19505](https://arxiv.org/abs/2412.19505)

#### MiLA: Multi-View Intensive-Fidelity Long-Term Video Generation World Model for Autonomous Driving
* **Authors**: Haoran Wang, Dong Liu, Haozhe Xie, Hui Liu, Eric Ma, Kun Yu, Liang Wang, Bo Wang
* **Links**: [arXiv:2503.15875](https://arxiv.org/abs/2503.15875)